from nodes.orchestrator_graph import build_orchestrator_graph
from nodes.render_node import render_node
from langgraph.graph import StateGraph,START, END
from typing import TypedDict
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import os
import json

# ============================================================
# ğŸ§  ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ© (API Keys)
# ============================================================
load_dotenv()
api_key = os.environ.get("OPENAI_API_KEY")
if not api_key:
    raise ValueError("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ OPENAI_API_KEY ÙÙŠ Ù…Ù„Ù .env")

# ============================================================
# ğŸ¤– Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
# ============================================================
llm = ChatOpenAI(
    model="gpt-5-mini",
    temperature=0.3,
    api_key=api_key
)

def get_llm():
    return llm

orchestrator_graph = build_orchestrator_graph(llm)

def build_main_app():
    g = StateGraph(dict)

    # âœ… return the WHOLE dict from orchestrator_graph, not just decisions
    def generate_node(state):
        state.setdefault("decisions", {})
        result = orchestrator_graph.invoke(state)
        # merge back into state so render_node receives {"decisions": {...}, ...}
        state.update(result or {})
        return state

    g.add_node("generate", generate_node)
    g.add_node("render", render_node)

    g.add_edge(START, "generate")
    g.add_edge("generate", "render")
    g.add_edge("render", END)
    return g.compile()

app = build_main_app()

def run_graph(user_data: dict):
    """
    ğŸ”¹ Ø¯Ø§Ù„Ø© Ø¨Ø³ÙŠØ·Ø© Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ LangGraph Ù…Ù† Flask
    """
    print("âš™ï¸ ØªØ´ØºÙŠÙ„ LangGraph...")
    result = {}
    try:
        for event in app.stream({"messages": [("user", str(user_data))]}):
            for value in event.values():
                result.update(value)
    except Exception as e:
        print("âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ´ØºÙŠÙ„ LangGraph:", e)
    return result






