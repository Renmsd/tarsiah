# nodes/orchestrator_graph.py
from langgraph.graph import StateGraph, START, END
from datetime import datetime, timedelta
from typing import TypedDict, Annotated
from nodes.field_map import FIELD_MAP
import operator
import asyncio
from concurrent.futures import ThreadPoolExecutor

# ---------------------------
# âœ… ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ù€ Graph
# ---------------------------
class State(TypedDict):
    raw_input: str
    decisions: dict
    sections: list[str]
    completed_sections: Annotated[list, operator.add]


# ---------------------------
# âœ… ØªÙˆØ§Ø±ÙŠØ® ØªÙ„Ù‚Ø§Ø¦ÙŠØ© (Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ)
# ---------------------------
def generate_auto_dates(issue_date: str | None):
    """
    Ø¥Ø°Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ø¯Ø®Ù„ Issue_Date â†’ Ù†Ø­Ø³Ø¨ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„ÙŠÙ‡Ø§,
    Ø¥Ø°Ø§ Ù„Ù… ÙŠØ¯Ø®Ù„ â†’ Ù†Ø³ØªØ®Ø¯Ù… ØªØ§Ø±ÙŠØ® Ø§Ù„ÙŠÙˆÙ….
    """
    if issue_date:
        base = datetime.strptime(issue_date, "%Y-%m-%d")
    else:
        base = datetime.today()

    return {
        "Issue_Date": base.strftime("%Y-%m-%d"),
        "Participation_Confirmation_Letter": (base + timedelta(days=2)).strftime("%Y-%m-%d"),
        "Submission_of_Questions_and_Inquiries": (base + timedelta(days=5)).strftime("%Y-%m-%d"),
        "Submission_of_Proposals": (base + timedelta(days=10)).strftime("%Y-%m-%d"),
        "Opening_of_Proposals": (base + timedelta(days=11)).strftime("%Y-%m-%d"),
        "Award_Decision_Date": (base + timedelta(days=17)).strftime("%Y-%m-%d"),
        "Commencement_of_Work": (base + timedelta(days=30)).strftime("%Y-%m-%d"),
    }



# ---------------------------
# âœ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ LLM (Ù…ØªÙˆØ§ÙÙ‚ sync/async)
# ---------------------------
async def _call_llm_async(llm, prompt):
    if hasattr(llm, "ainvoke"):
        try:
            result = await llm.ainvoke(prompt)
            return getattr(result, "content", result).strip()
        except Exception:
            pass

    loop = asyncio.get_running_loop()

    def sync():
        try:
            result = llm.invoke(prompt)
            return getattr(result, "content", result).strip()
        except Exception:
            return "ØªØ¹Ø°Ø± ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙÙ‚Ø±Ø© Ø¨Ø³Ø¨Ø¨ Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ."

    return await loop.run_in_executor(ThreadPoolExecutor(max_workers=6), sync)


# ---------------------------
# âœ… orchestrator: ÙŠØ­Ø¶Ù‘Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ø®ØªÙŠØ§Ø± Ø§Ù„ sections
# ---------------------------
def orchestrator(state: State):
    from flask import session

    # âœ… ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù„Ø¯ÙŠÙ†Ø§ decisions
    state.setdefault("decisions", {})
    decisions = state["decisions"]

    # âœ… raw_input ÙŠØ£ØªÙŠ Ù…Ù† run_graph(user_data)
    raw = state.get("raw_input")

    # âœ… Ø¥Ø°Ø§ raw dict â†’ Ù†Ø¯Ù…Ø¬Ù‡ Ù…Ø¨Ø§Ø´Ø±Ø©
    if isinstance(raw, dict):
        decisions.update(raw)

    # âœ… Ø¥Ø°Ø§ raw string JSON â†’ Ù†Ø­ÙˆÙ„Ù‡ ÙˆÙ†Ø¶ÙŠÙÙ‡
    elif isinstance(raw, str):
        try:
            import json
            decisions.update(json.loads(raw))
        except Exception:
            pass
    # âœ… Ø¶Ù…Ø§Ù† ÙˆØ¬ÙˆØ¯ Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø¬Ø²Ø§Ø¡Ø§Øª Ø­ØªÙ‰ Ù„Ùˆ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø§ Ø§Ø®ØªØ§Ø± Ø´ÙŠØ¡
    for key in ["Penalty_Deduction", "Penalty_Execute_On_Vendor", "Penalty_Suspend", "Penalty_Termination"]:
        decisions.setdefault(key, "")


    # âœ… ØªÙˆØ§Ø±ÙŠØ® ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
    issue_date_input = decisions.get("Issue_Date")
    decisions.update(generate_auto_dates(issue_date_input))

    # âœ… ØªØ­ÙƒÙ… Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ø®ØªÙŠØ§Ø±ÙŠØ© Ø­Ø³Ø¨ checkbox
    include = session.get("include_sections", {})
    sections = []

    for key, v in FIELD_MAP.items():
        if v == "llm":
            # Ø¥Ø°Ø§ Ø§Ù„Ù‚Ø³Ù… Ø§Ø®ØªÙŠØ§Ø±ÙŠ ÙˆÙ„Ù… ÙŠØªÙ… ØªÙØ¹ÙŠÙ„Ù‡ â†’ ØªØ¬Ø§Ù‡Ù„Ù‡
            if key in include and not include[key]:
                print(f"ğŸš« SKIP section: {key}")
                continue

            sections.append(key)
        # âœ… Inject raw_input into decisions so PROMPTS can use {raw_input}
    decisions["raw_input"] = state.get("raw_input")


    return {
        "sections": sections,
        "decisions": decisions
    }



# ---------------------------
# âœ… ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„ Ø§Ù„ÙÙ‚Ø±Ø§Øª (Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ Ù„Ù„Ø³Ø±Ø¹Ø©)
# ---------------------------
# ---------------------------
# âœ… ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„ Ø§Ù„ÙÙ‚Ø±Ø§Øª (Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ Ù„Ù„Ø³Ø±Ø¹Ø©) + DEBUG
# ---------------------------
def generate_all_sections(state, llm):
    from flask import session

    state.setdefault("decisions", {})
    d = state["decisions"]
    sections = state.get("sections", [])

    # âœ… DEBUG â€” Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠ ØªØµÙ„ Ù„Ù„Ù€ LLM
    print("\n============================")
    print("âœ… DEBUG | Decisions sent to LLM:")
    for k, v in d.items():
        print(f" - {k}: {v}")
    print("============================\n")

    from nodes.prompts import PROMPTS

    async def _parallel_generate():
        tasks, keys = [], []

        for sec in sections:
            if sec in PROMPTS:
                prompt = PROMPTS[sec].format(**d)

                # âœ… DEBUG â€” Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„ÙØ¹Ù„ÙŠ Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„
                print(f"\nğŸŸ¦ Generating section: {sec}")
                print("ğŸ”¹ Final Prompt Sent to LLM:\n")
                print(prompt)
                print("---------------------------------------------------\n")

                tasks.append(_call_llm_async(llm, prompt))
                keys.append(sec)

        results = await asyncio.gather(*tasks, return_exceptions=True)

        for sec, result in zip(keys, results):
            d[sec] = result if isinstance(result, str) else "ØªØ¹Ø°Ø± ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†Øµ."

    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    loop.run_until_complete(_parallel_generate())
    loop.close()

    return {"decisions": d}



# ---------------------------
# âœ… synthesize output
# ---------------------------
def synthesizer(state):
    return {"decisions": state.get("decisions", {})}


# ---------------------------
# âœ… build graph
# ---------------------------
def build_orchestrator_graph(llm):
    g = StateGraph(State)
    g.add_node("orchestrator", orchestrator)
    g.add_node("generate_all_sections", lambda s: generate_all_sections(s, llm))
    g.add_node("synthesizer", synthesizer)

    g.add_edge(START, "orchestrator")
    g.add_edge("orchestrator", "generate_all_sections")
    g.add_edge("generate_all_sections", "synthesizer")
    g.add_edge("synthesizer", END)

    return g.compile()
